---
title: "Mandatory Assignment 2 AEF"
author: "ncx951 & dsc579"
date: "`r Sys.Date()`"
output:
  pdf_document: default
  html_document: default
---



```{r include=FALSE}
# Packages

# Graphics
library(ggplot2)
library(cowplot)
library(lattice)
library(hexbin)
library(gridExtra)
library(reshape2)
library(grid)
library(tidyverse)
library(tidymodels)


# Table formatting
library(xtable)
library(pander)
library(kableExtra)
library(vtable)

# Machine Learning
library(keras)
library(tensorflow)
library(Metrics)

# Other
library(readr)
library(dplyr)
library(lubridate)
library(RSQLite)
library(knitr)



```


# Excercise 1

We load in the dataset and select the following variables based on figure 5 from the Gu et al (2020) paper. We choose the among the variables that contributes the most to overall model contribution. 


```{r cache=TRUE}
# Load in the dataset
tidy_finance <- dbConnect(
  SQLite(),
  "tidy_finance_ML.sqlite",
  extended_types = TRUE
)


stock_characteristics_monthly <- tbl(tidy_finance, "stock_characteristics_monthly") |> collect()
```




```{r cache=TRUE}

# Filtering out characteristics and only include data from 2005-01-01
stock_characteristics_monthly <- stock_characteristics_monthly |>
               select(permno, month, ret_excess, mktcap_lag, sic2, 
                      macro_bm, macro_ntis, macro_tbl, macro_dfy, 
                      characteristic_mom1m, characteristic_mom12m, characteristic_chmom, characteristic_maxret, characteristic_mvel1) |>     
               filter(month >= "2005-01-01") |>
               drop_na()

# Renaming column names according to the names from the Gu et al paper

colnames(stock_characteristics_monthly) <- c("permno", "month", "ret_excess", "mktcap_lag", "sic2", 
                                             "m_bm", "m_ntis", "m_tbl", "m_dfy",
                                             "c_mom1m", "c_mom12m", "c_chmom", "c_maxret", "c_mvel1")

# Turn sic2 into a factor instead of numerical value
stock_characteristics_monthly$sic2 <- as.factor(stock_characteristics_monthly$sic2)

# Convert month column to Date format
stock_characteristics_monthly$month <- as.Date(stock_characteristics_monthly$month)

dbDisconnect(tidy_finance)
remove(tidy_finance)

```

The dataset includes observations from January 1st 2005 and onward. 

We perform EDA for the number of unique firms (permno) in each industry classification (sic2) for each month. 

```{r fig.height=5, fig.width=10}


# Counting how many firms (permno) thats in each industry (sic2) for each month
no_industry <- select(stock_characteristics_monthly, permno, month, sic2) |>
                group_by(month, sic2) |>
                summarise(n = n())
 
# Creates a stacked barplot
ggplot(no_industry, aes(fill=sic2, y=n, x=month)) +
  geom_bar(position = "stack", stat = "identity") +
  ggtitle("Number of unique firms (permno) in each industry classification (sic2) for each month") + 
  xlab("Time") + 
  ylab("No. firms") +
  scale_fill_discrete(name = "Industry classifications (sic2)")

```






Summary table of our choosen variables.

```{r}


stock_characteristics_monthly_summary <- stock_characteristics_monthly |>
  select(-permno, -month, -sic2) |>
  pivot_longer(cols = everything(), names_to = "Variables", values_to = "Value") |>
  group_by(Variables) |>
  summarize_all(list(mean = mean, 
                     sd = sd,
                     min = min,
                     median = median,
                     max = max)) |>
  knitr::kable(booktabs = TRUE, digits = 2, caption = "Summary statistics of the predictors") |> 
  kable_paper("hover", full_width = T) |>  
  group_rows("Stock Characteristics", 1, 5) |> 
  group_rows("Macro Characteristics", 6, 9) |> 
  group_rows("Initial Variables", 10, 11)

stock_characteristics_monthly_summary

```




# Excercise 2

Gu et al. (2020) describe an assetâ€™s excess return as an additive prediction error model the following way:

$$r_{i,t+1} = E_t(r_{i,t+1}) + \varepsilon_{i,t+1} \quad \text{where} \quad E_t(r_{i,t+1}) = g(z_{i,t})$$
Where $g(z_{i,t})$ is a function of the $P$-dimensional vector $z_{i,t}$ of predictor variables. 

As stated in the paper this would be considered a very flexible model, however it imposes some important restrictions. First the $g(\cdot)$ function depends neither on the individual stock or time period. It thus leverages of the information from the entire dataset. The functional form thus doesn't adjust by time period or for specific stocks. For example one variable could have a larger explanatory power in the beginning of the time period but much lesser towards the end. The effect from the predictor would still remain constant, and could also relate to overfitting the model.  The model also assumes that the prediction error $\varepsilon_{i,t+1}$ is additive and independent of the predictor variables, which may not hold in reality.


# Excercise 3

Making the train-validation-test split with 20% of the last observations as test data and make 20% of the train data into validation.


```{r}

# Splitting into a 80/20 test-train split

split_train <- initial_time_split(
  stock_characteristics_monthly |>
    select(-permno, -month),
  prop = 4/5
)

# Further splitting 20% of training data into validation

new_split_train <- initial_time_split(
  training(split_train), 
  prob = 4/5
)


# Making the recipe        
rec <- recipe(ret_excess ~ ., data = new_split_train) |>
  step_interact(terms = ~contains("c_"):contains("m_")) |>
  step_dummy(sic2, one_hot = TRUE) |>
  step_normalize(all_predictors()) |>
  step_center(ret_excess, skip = TRUE)


# Preprocess the training data
prep_train <- prep(rec, training(new_split_train))
data_train <- bake(prep_train, new_data = training(new_split_train))

# Preprocess the validation data

prep_val <- prep(rec, testing(new_split_train))
data_val <- bake(prep_train, new_data = testing(new_split_train))

# Preprocess the testing data
prep_test <- prep(rec, testing(split_train))
data_test <- bake(prep_train, new_data = testing(split_train))


```


# Excercise 4

Neural Network

```{r}



lambda <- 0.0001
dropout_rate <- 0.05

NN_model <- keras_model_sequential() |>
    layer_dense(units = 10, activation = "sigmoid", input_shape = 100, kernel_regularizer = regularizer_l2(lambda)) |>
    layer_dropout(rate=dropout_rate) |>
    layer_dense(units = 10, activation = "sigmoid", kernel_regularizer = regularizer_l2(lambda)) |>
    layer_dropout(rate=dropout_rate) |>
    layer_dense(units = 10, activation = "sigmoid", kernel_regularizer = regularizer_l2(lambda)) |>
    layer_dropout(rate=dropout_rate) |>
    layer_dense(units = 1, activation = "linear") |>

  compile(
    loss = 'mse',
    optimizer = optimizer_rmsprop(learning_rate=0.001, rho=0.9)    
)
 
 
NN_fit <- NN_model |>
  fit(
    x = data_train |>
      select(-ret_excess) |>
      as.matrix(),
    y = data_train |>
      pull(ret_excess),
    epochs = 20, batch_size = 128, verbose = FALSE
  )


```


```{r}
#############################
# This code is used for optimizing the NN.
# It takes a very long time to run and uses a lot of RAM storage.
# We don't recommend running it and have provided a summary table below with the results.
############################

# # Define the hyperparameters you want to tune
# nodes <- c(5, 10, 15)
# lambdas <- c(0.0001, 0.001, 0.01)
# 
# # Create an empty data frame to store the results
# results <- data.frame()
# 
# # Perform a grid search over the hyperparameters
# for (n in nodes) {
#   for (l in lambdas) {
#     # Define the model with the current hyperparameters
#     NN_model <- keras_model_sequential() %>%
#       layer_dense(units = n, activation = "sigmoid", input_shape = 100, kernel_regularizer = regularizer_l2(l)) %>%
#       layer_dense(units = n, activation = "sigmoid", kernel_regularizer = regularizer_l2(l)) %>%
#       layer_dense(units = 1, activation = "linear") %>%
#       compile(loss = "mse", optimizer = optimizer_rmsprop(learning_rate = 0.001, rho = 0.9))
# 
#     # Train the model
#     NN_fit <- NN_model %>%
#       fit(x = data_train %>% select(-ret_excess) %>% as.matrix(),
#           y = data_train %>% pull(ret_excess),
#           epochs = 20, batch_size = 128, verbose = FALSE)
# 
#     # Make predictions on the validation data
#     NN_pred <- NN_model %>% predict(data_val %>% select(-ret_excess) %>% as.matrix())
# 
#     # Compute MSE
#     mse_NN <- mse(NN_pred, data_val$ret_excess)
# 
#     # Add the results to the data frame
#     results <- rbind(results, data.frame(NumNodes = n, Lambda = l, MSE = mse_NN))
#   }
# }


```


```{r}

# Display the results in a table

NN_tuning_summary <- matrix(c(
  5, 0.0001, 0.02829,
  10, 0.0001, 0.02834,
  15, 0.0001, 0.02832,
  5, 0.001, 0.02872,
  10, 0.001, 0.02884,
  15, 0.001, 0.02880,
  5, 0.01, 0.02874,
  10, 0.01, 0.02874,
  15, 0.01, 0.02904
), ncol = 9)

rownames(NN_tuning_summary) <- c("No. neurons at each layer", "lambda for L2-regularization", "MSE")

NN_tuning_summary |> knitr::kable(booktabs = TRUE, digits = 5, caption = "Neural network performance for different hyperparameters") |> kable_paper("hover", full_width = T)

```


```{r}

# This is the final model we decide to go with. 

NN_model <- keras_model_sequential() |>
      layer_dense(units = 5, activation = "sigmoid", input_shape = 100, kernel_regularizer = regularizer_l2(0.0001)) |>
      layer_dense(units = 5, activation = "sigmoid", kernel_regularizer = regularizer_l2(0.0001)) |>
      layer_dense(units = 1, activation = "linear") |>
      compile(loss = "mse", optimizer = optimizer_rmsprop(learning_rate = 0.001, rho = 0.9))

# Train the model
NN_fit <- NN_model |>
      fit(x = data_train |> select(-ret_excess) |> as.matrix(),
          y = data_train |> pull(ret_excess),
          epochs = 20, batch_size = 128, verbose = FALSE)

# Make predictions on the validation data
NN_pred <- NN_model |> predict(data_val|> select(-ret_excess) |> as.matrix())


```

# Excercise 5


```{r}
# Add the month variable back to the data_test dataset
data_test <- cbind(testing(split_train)[, c("month", "permno")], data_test)

# 1. Make predictions on the test dataset
NN_test_pred <- NN_model |>
  predict(data_test |>
            select(-ret_excess) |>
            as.matrix())

# Add predictions back to the test dataset
data_test$predictions <- NN_test_pred

# 2. Sort stocks into deciles based on the model's forecasts
data_test <- data_test |>
  group_by(month = lubridate::floor_date(data_test$month, "month")) |>
  mutate(decile = ntile(predictions, 10))

# 3. Reconstitute portfolios each month using value weights
monthly_returns <- data_test |>
  group_by(month, decile) |>
  summarize(weighted_ret = sum(ret_excess * mktcap_lag) / sum(mktcap_lag),
            .groups = "drop")

# 4. Construct a zero-net-investment portfolio
zero_net_investment <- monthly_returns |>
  filter(decile %in% c(1, 10)) |>
  group_by(month) |>
  summarize(returns = weighted_ret[decile == 10] - weighted_ret[decile == 1],
            .groups = "drop")

# 5. Discuss the findings and evaluate the portfolio performance
overall_return <- prod(1 + zero_net_investment$returns) - 1
avg_monthly_return <- mean(zero_net_investment$returns)



```






